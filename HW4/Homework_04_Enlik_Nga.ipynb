{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cedtXySEYb28"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"><b></b>\n",
    "<h1><center> <font color='black'> Homework 04  </font></center></h1>\n",
    "<h2><center> <font color='black'> Cross-sell / Up-sell using Recommendations </font></center></h2>\n",
    "<h2><center> <font color='black'> Due date : 26 April 23:59 </font></center></h2>    \n",
    "<h2><center> <font color='black'> BDA - University of Tartu - Spring 2020</font></center></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dHyOkasBYb3D"
   },
   "source": [
    "# Homework instructions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-pvZUeIYb3G"
   },
   "source": [
    "- Insert your team member names and student IDs in the field \"Team mates\" below. If you are not working in a team please insert only your name, surname and student ID \n",
    "\n",
    "- The accepted submission formats are Colab links or .ipynb files. If you are submitting Colab links please make sure that the privacy settings for the file is public so we can access your code. \n",
    "\n",
    "- The submission will automatically close at 12:00 am, so please make sure you have enough time to submit the homework. \n",
    "\n",
    "- Only one of the teammates should submit the homework. We will grade and give points to both of you! \n",
    "\n",
    "- You do not necessarily need to work on Colab. Especially as the size and the complexity of datasets will increase through the course, you can install jupyter notebooks locally and work from there.\n",
    "\n",
    "- If you do not understand what a question is asking for, please ask in Moodle. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9OWlFadiYb3I"
   },
   "source": [
    "**<h2><font color='red'>Team mates:</font></h2>**\n",
    "\n",
    "\n",
    "<font color='red'>Name Surname: Enlik -</font>&emsp;   <font color='red'>Student ID: B96323</font>\n",
    "\n",
    "\n",
    "<font color='red'>Name Surname: Thi Thuy Nga Vu</font>&emsp;   <font color='red'>Student ID: B88416</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "boFT1CkoYb3K"
   },
   "source": [
    "# 1.  Market Basket Analysis (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3hBebgbYb3M"
   },
   "source": [
    "**1.1 Consider the following businesses and think about one case of cross selling and one case of up selling techniques they could use. This question is not restricted to only traditional, standard examples. If you wish you can provide something that you would like these businesses to do. (1 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HxMUA01DYb3P"
   },
   "source": [
    "a. An OnlineTravel Agency like Booking.com or AirBnB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RODzp7BPYb3T"
   },
   "source": [
    "<font color='red'> **Cross selling:**</font>\n",
    "\n",
    "<font color='red'> **Up selling:**</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qbw_w9p1Yb3U"
   },
   "source": [
    "b. A software company which produces products related to cyber security like Norton, Kaspersky, Avast and similar ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j0SyXnB6Yb3W"
   },
   "source": [
    "<font color='red'> **Cross selling:**</font>\n",
    "\n",
    "<font color='red'> **Up selling:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7EUCv8TtYb3X"
   },
   "source": [
    "c. A company that sells cell phones "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NFHO-dI6Yb3Y"
   },
   "source": [
    "<font color='red'> **Cross selling:**</font>\n",
    "\n",
    "<font color='red'> **Up selling:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_wnH4-lrYb3a"
   },
   "source": [
    "d. A supermarket like Konsum, Rimi, Maxima etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I4CNtNYBYb3b"
   },
   "source": [
    "<font color='red'> **Cross selling:**</font>\n",
    "\n",
    "<font color='red'> **Up selling:**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLp7o0cdYb3c"
   },
   "source": [
    "**1.2 One of the techniques which we discussed in the theory lecture for recommendater systems is Market Basket Analysis. The aim is to study the products bought frequently together and to recommend product in bunndles. Let's suppose that our client is a retail company that has an online shop. They have given to us the OnlineRetail.csv dataset (we have previously used this dataset in our practice sessions 03). It contains data about the online sales of several products. The client or  wants to know which product bundles to promote. Let us find the 5 association rules with the highest lift.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7HLlQ30Yb3e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('OnlineRetailPurchase.csv', header=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWBRFwuUYb3l",
    "outputId": "56e2ce1f-6d98-4ed1-aa07-2c6c9c268b11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kcjIimkHYb35"
   },
   "source": [
    "**1.2 Use describe function from pandas to get statistical information about the values in the dataframe. Do you notice something which might not be correct? If so please perform the necessary operations. (Hint: Remember what we did in the practice session 03)(0.25 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RakInjZBY4Wu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>7709.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.828600</td>\n",
       "      <td>3.837412</td>\n",
       "      <td>15615.462576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>104.322417</td>\n",
       "      <td>14.310148</td>\n",
       "      <td>1756.540802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-9360.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>14388.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>15605.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>17228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2880.000000</td>\n",
       "      <td>887.520000</td>\n",
       "      <td>18239.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Quantity     UnitPrice    CustomerID\n",
       "count  10000.000000  10000.000000   7709.000000\n",
       "mean       7.828600      3.837412  15615.462576\n",
       "std      104.322417     14.310148   1756.540802\n",
       "min    -9360.000000      0.000000  12395.000000\n",
       "25%        1.000000      1.250000  14388.000000\n",
       "50%        2.000000      2.510000  15605.000000\n",
       "75%        8.000000      4.210000  17228.000000\n",
       "max     2880.000000    887.520000  18239.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n"
     ]
    }
   ],
   "source": [
    "print(sum(df['Quantity'] < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quantity</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9870.000000</td>\n",
       "      <td>9870.000000</td>\n",
       "      <td>7609.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.169301</td>\n",
       "      <td>3.837023</td>\n",
       "      <td>15620.763832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45.747927</td>\n",
       "      <td>14.391451</td>\n",
       "      <td>1755.451331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>14388.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.510000</td>\n",
       "      <td>15640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.210000</td>\n",
       "      <td>17228.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2880.000000</td>\n",
       "      <td>887.520000</td>\n",
       "      <td>18239.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Quantity    UnitPrice    CustomerID\n",
       "count  9870.000000  9870.000000   7609.000000\n",
       "mean      9.169301     3.837023  15620.763832\n",
       "std      45.747927    14.391451   1755.451331\n",
       "min       1.000000     0.000000  12395.000000\n",
       "25%       1.000000     1.250000  14388.000000\n",
       "50%       3.000000     2.510000  15640.000000\n",
       "75%       8.000000     4.210000  17228.000000\n",
       "max    2880.000000   887.520000  18239.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all rows with quantity less than zero\n",
    "df = df[df['Quantity'] >= 0]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J5a0X9dtYb4K"
   },
   "source": [
    "**1.3 Create a dataframe name as \"Basket\", where each row has an distintive value of InvoiceNo and each column has a distinctive Description. The cells in the table contain the count of each item (Description) mentioned in one invoice. For example basket.loc['536365','WHITE HANGING HEART T-LIGHT HOLDER'] has a value of 1 because the product with WHITE HANGING HEART T-LIGHT HOLDER was entered  only once in the invoice 536365. Hint: Remember the function you used in Homework 1 for a similar task or in practice session no.07 (0.25 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4lUPlKAYb4L"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>Description</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">536365</th>\n",
       "      <th>CREAM CUPID HEARTS COAT HANGER</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLASS STAR FROSTED T-LIGHT HOLDER</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNITTED UNION FLAG HOT WATER BOTTLE</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RED WOOLLY HOTTIE WHITE HEART.</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SET 7 BABUSHKA NESTING BOXES</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">537224</th>\n",
       "      <th>WASHROOM METAL SIGN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAY OUT METAL SIGN</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE BELL HONEYCOMB PAPER</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WHITE BELL HONEYCOMB PAPER GARLAND</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WOODEN BOX OF DOMINOES</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9506 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Count\n",
       "InvoiceNo Description                               \n",
       "536365    CREAM CUPID HEARTS COAT HANGER           1\n",
       "          GLASS STAR FROSTED T-LIGHT HOLDER        1\n",
       "          KNITTED UNION FLAG HOT WATER BOTTLE      1\n",
       "          RED WOOLLY HOTTIE WHITE HEART.           1\n",
       "          SET 7 BABUSHKA NESTING BOXES             1\n",
       "...                                              ...\n",
       "537224    WASHROOM METAL SIGN                      1\n",
       "          WAY OUT METAL SIGN                       1\n",
       "          WHITE BELL HONEYCOMB PAPER               2\n",
       "          WHITE BELL HONEYCOMB PAPER GARLAND       2\n",
       "          WOODEN BOX OF DOMINOES                   1\n",
       "\n",
       "[9506 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# //TODO \n",
    "# Reference from Lab 07 - Reommendations System\n",
    "## get number of ratings given by every user\n",
    "# df_users_cnt = pd.DataFrame(df_ratings_drop_movies.groupby('userId').size(), columns=['count'])\n",
    "# df_users_cnt.head()\n",
    "\n",
    "basket = pd.DataFrame(df.groupby(['InvoiceNo', 'Description']).size(), columns=['Count'])\n",
    "# basket = pd.DataFrame(df.groupby(['InvoiceNo', 'Description']).sum().unstack().reset_index().set_index('InvoiceNo'))\n",
    "# basket.rename_axis(None, inplace=True)\n",
    "basket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Count    1\n",
       "Name: (536365, WHITE HANGING HEART T-LIGHT HOLDER), dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket.loc['536365','WHITE HANGING HEART T-LIGHT HOLDER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Count    2\n",
       "Name: (537224, WHITE BELL HONEYCOMB PAPER ), dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket.loc['537224','WHITE BELL HONEYCOMB PAPER ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Count    5\n",
       "Name: (536412, 12 DAISY PEGS IN WOOD BOX), dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket.loc['536412','12 DAISY PEGS IN WOOD BOX']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rwKSVg3Yb4d"
   },
   "source": [
    "**1.4 Some products are mentioned more than once in one invoice. You can check the maximum number for each column to \n",
    "verify. Modify your dataframe such that every cell which has a value higher than one will be replaced with 1. If the cell has the value 0 it will remain the same. (0.25 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BO17Wy1Yb4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9506.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Count\n",
       "count  9506.0\n",
       "mean      1.0\n",
       "std       0.0\n",
       "min       1.0\n",
       "25%       1.0\n",
       "50%       1.0\n",
       "75%       1.0\n",
       "max       1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference\n",
    "# https://kite.com/python/answers/how-to-change-values-in-a-pandas-dataframe-column-based-on-a-condition-in-python\n",
    "basket_sets = basket.copy()\n",
    "basket_sets.loc[basket_sets.Count > 1, \"Count\"] = 1\n",
    "basket_sets.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KfWgocGTYb4k"
   },
   "source": [
    "**1.5 We do not need to spend time on calculating the association rules by ourselves as there already exists a package for python to do so, called mlxtend. We are going to use the mlxtend package to find frequent items bought together and then create some rules on what to recomend to a user based on what he/she/they have bought. We have given you the first part of the code which calculates the frequent items bought together.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rCw4ii7tYb4l"
   },
   "outputs": [],
   "source": [
    "#!pip install mlxtend\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import mlxtend as ml\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQBjILk5Yb4p"
   },
   "outputs": [],
   "source": [
    "# Mlxtend has implemented Apriori, a popular algorithm for extracting frequent itemsets \n",
    "# We can change the value of minimum support but it will \n",
    "# But as well we get less useful results for the next step. \n",
    "# Setting use_colnames=True to convert the returned integer indices into item names\n",
    "\n",
    "# TODO\n",
    "# frequent_itemsets = apriori(basket_sets, min_support=0.03, use_colnames=True)\n",
    "# frequent_itemsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GcF5RyYRYb4y"
   },
   "source": [
    "**Please read the documentation of the associaton rules function in mlextend [here](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/) and then complete the code so we get the 5 rules with the highest lift. Print those rules.  In the output antecedents represent if .... clause and consequents represent else... clause. For example if user bought product basket A then  the algorithm recommends product basket B. (0.25 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FLpV1FkKYb41"
   },
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "# rules = association_rules(..., metric=...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRqo0ek4Yb47"
   },
   "source": [
    "# 2. Collaborative filtering (3.5 points )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_U1OvsCJYb48"
   },
   "source": [
    "We are going to use Books.csv dataset which contains  ratings from Amazon website and the data has the following features:\n",
    "\n",
    "UserID: The ID of the users who read the books\n",
    "\n",
    "BookTitle: The title of the book\n",
    "\n",
    "Book-Rating: A rating given to the book in a scale from 0 to 10\n",
    "\n",
    "Below we are going to perform the same steps we did with movies dataset in the practice session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-wOm7yLYb49"
   },
   "source": [
    "**2.0 Load the dataset and take a look at the books titles. Please pick one of them which you like (or think that you would like) the most.(0.1 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_2CgjU6Yb4-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>BookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6181</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  Book-Rating             BookTitle\n",
       "0    6181            0  Flesh Tones: A Novel\n",
       "1      62            5  Flesh Tones: A Novel\n",
       "2     163            0  Flesh Tones: A Novel\n",
       "3     212            5  Flesh Tones: A Novel\n",
       "4     250            9  Flesh Tones: A Novel"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv(\"Books.csv\", header=0)\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>BookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>6198</td>\n",
       "      <td>7</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>6283</td>\n",
       "      <td>10</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821</th>\n",
       "      <td>56</td>\n",
       "      <td>9</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Boo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID  Book-Rating                                          BookTitle\n",
       "1818    6198            7  Harry Potter and the Order of the Phoenix (Boo...\n",
       "1819    6283           10  Harry Potter and the Order of the Phoenix (Boo...\n",
       "1820       7            0  Harry Potter and the Order of the Phoenix (Boo...\n",
       "1821      56            9  Harry Potter and the Order of the Phoenix (Boo...\n",
       "1822     117            0  Harry Potter and the Order of the Phoenix (Boo..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick my favorite book = 'Harry Potter and the Order of the Phoenix (Book 5)'\n",
    "books[books['BookTitle'] == 'Harry Potter and the Order of the Phoenix (Book 5)'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>BookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>6198</td>\n",
       "      <td>7</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Boo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID  Book-Rating                                          BookTitle\n",
       "1818    6198            7  Harry Potter and the Order of the Phoenix (Boo..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.iloc[[1818]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q_f2ywpLYb5J"
   },
   "source": [
    "**2.1 Our next step will be to perform user based collaborative filtering using KNN algorithm. As KNN algorithm does not accept strings, use a Label Encoder for BookTitle column.After that reshape the books matrix using pivot so every column will be a UserID and every row a BookTitle. (0.45 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Gs_CAGKYb5K"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>BookID_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6181</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3663</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3665</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3666</td>\n",
       "      <td>3</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3668</td>\n",
       "      <td>9</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3670</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID  Book-Rating  BookID_Encoded\n",
       "0       6181            0             124\n",
       "1         62            5             124\n",
       "2        163            0             124\n",
       "3        212            5             124\n",
       "4        250            9             124\n",
       "...      ...          ...             ...\n",
       "9995    3663            0             333\n",
       "9996    3665            0             333\n",
       "9997    3666            3             333\n",
       "9998    3668            9             333\n",
       "9999    3670            0             333\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference\n",
    "# https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "books_encoded = books.apply(LabelEncoder().fit_transform)\n",
    "books_encoded = books_encoded.rename(columns={\"BookTitle\": \"BookID_Encoded\"})\n",
    "books_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>BookID_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6181</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3663</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3665</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3666</td>\n",
       "      <td>3</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>3668</td>\n",
       "      <td>9</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>3670</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9998 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID  Book-Rating  BookID_Encoded\n",
       "0       6181            0             124\n",
       "1         62            5             124\n",
       "2        163            0             124\n",
       "3        212            5             124\n",
       "4        250            9             124\n",
       "...      ...          ...             ...\n",
       "9995    3663            0             333\n",
       "9996    3665            0             333\n",
       "9997    3666            3             333\n",
       "9998    3668            9             333\n",
       "9999    3670            0             333\n",
       "\n",
       "[9998 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_encoded_no_dup = books_encoded.drop_duplicates(['UserID', 'BookID_Encoded'])\n",
    "books_encoded_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336, 6292)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>UserID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6282</th>\n",
       "      <th>6283</th>\n",
       "      <th>6284</th>\n",
       "      <th>6285</th>\n",
       "      <th>6286</th>\n",
       "      <th>6287</th>\n",
       "      <th>6288</th>\n",
       "      <th>6289</th>\n",
       "      <th>6290</th>\n",
       "      <th>6291</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BookID_Encoded</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "UserID          0     1     2     3     4     5     6     7     8     9     \\\n",
       "BookID_Encoded                                                               \n",
       "0                0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1                0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2                0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3                0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4                0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "UserID          ...  6282  6283  6284  6285  6286  6287  6288  6289  6290  \\\n",
       "BookID_Encoded  ...                                                         \n",
       "0               ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "1               ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "2               ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "3               ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "4               ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   \n",
       "\n",
       "UserID          6291  \n",
       "BookID_Encoded        \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "\n",
       "[5 rows x 6292 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference\n",
    "# https://datascienceplus.com/building-a-book-recommender-system-the-basics-knn-and-matrix-factorization/\n",
    "# Practice Lab 07\n",
    "\n",
    "books_matrix = books_encoded_no_dup.pivot(index = 'BookID_Encoded', columns = 'UserID', values = 'Book-Rating').fillna(0)\n",
    "print(books_matrix.shape)\n",
    "books_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4RwLx90KYb5R"
   },
   "source": [
    "**2.2 Build a sparse matrix for books data and show it. (0.45 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uwVtesasYb5U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix:\n",
      "  (1, 6228)\t5.0\n",
      "  (2, 365)\t7.0\n",
      "  (2, 5110)\t9.0\n",
      "  (2, 5226)\t10.0\n",
      "  (2, 6209)\t10.0\n",
      "  (3, 91)\t7.0\n",
      "  (3, 135)\t8.0\n",
      "  (3, 139)\t10.0\n",
      "  (3, 258)\t9.0\n",
      "  (3, 429)\t6.0\n",
      "  (3, 760)\t5.0\n",
      "  (3, 821)\t6.0\n",
      "  (3, 869)\t9.0\n",
      "  (3, 984)\t10.0\n",
      "  (3, 1328)\t5.0\n",
      "  (3, 1425)\t10.0\n",
      "  (3, 1781)\t2.0\n",
      "  (3, 1815)\t9.0\n",
      "  (3, 1820)\t9.0\n",
      "  (3, 1951)\t8.0\n",
      "  (3, 2360)\t8.0\n",
      "  (3, 2384)\t8.0\n",
      "  (3, 2449)\t9.0\n",
      "  (3, 2468)\t7.0\n",
      "  (3, 2956)\t5.0\n",
      "  :\t:\n",
      "  (333, 3411)\t4.0\n",
      "  (333, 3416)\t1.0\n",
      "  (333, 3433)\t8.0\n",
      "  (333, 3445)\t5.0\n",
      "  (333, 3450)\t2.0\n",
      "  (333, 3456)\t4.0\n",
      "  (333, 3461)\t8.0\n",
      "  (333, 3491)\t2.0\n",
      "  (333, 3497)\t1.0\n",
      "  (333, 3501)\t4.0\n",
      "  (333, 3518)\t8.0\n",
      "  (333, 3519)\t3.0\n",
      "  (333, 3527)\t7.0\n",
      "  (333, 3543)\t7.0\n",
      "  (333, 3546)\t9.0\n",
      "  (333, 3547)\t7.0\n",
      "  (333, 3573)\t5.0\n",
      "  (333, 3575)\t1.0\n",
      "  (333, 3581)\t7.0\n",
      "  (333, 3597)\t3.0\n",
      "  (333, 3602)\t6.0\n",
      "  (333, 3666)\t3.0\n",
      "  (333, 3668)\t9.0\n",
      "  (333, 6250)\t2.0\n",
      "  (333, 6277)\t9.0\n"
     ]
    }
   ],
   "source": [
    "# Reference - Practice Lab 07\n",
    "# transform matrix to scipy sparse matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "books_matrix_sparse = csr_matrix(books_matrix.values)\n",
    "print(f\"Sparse matrix:\\n{books_matrix_sparse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrKKbiRJYb5g"
   },
   "source": [
    "**2.3 Build and train two different KNN models (use cosine metric for similarity for both) but with different n_neighbours, that is 2 and 10. Recommend top 5 books based on your favourite one from 2.0 in both cases (1 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bHN1hcjOYb5h"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn_1 = NearestNeighbors(metric = 'cosine', algorithm = 'brute', n_neighbors=2)\n",
    "model_knn_2 = NearestNeighbors(metric = 'cosine', algorithm = 'brute', n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn_1.fit(books_matrix_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "                 metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn_2.fit(books_matrix_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookID_Encoded</th>\n",
       "      <th>BookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>252</td>\n",
       "      <td>Rites of Passage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295</td>\n",
       "      <td>The Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150</td>\n",
       "      <td>Help!: Level 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271</td>\n",
       "      <td>The Amsterdam Connection : Level 4 (Cambridge ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BookID_Encoded                                          BookTitle\n",
       "0             124                               Flesh Tones: A Novel\n",
       "1             252                                   Rites of Passage\n",
       "2             295                                       The Notebook\n",
       "3             150                                     Help!: Level 1\n",
       "4             271  The Amsterdam Connection : Level 4 (Cambridge ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataframe for\n",
    "# Reference\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html\n",
    "books_encoded_title = pd.concat([books_encoded, books], join=\"outer\", axis = 1)\n",
    "books_encoded_title = books_encoded_title[['BookID_Encoded', 'BookTitle']]\n",
    "books_encoded_title = books_encoded_title.drop_duplicates()\n",
    "books_encoded_title = books_encoded_title.reset_index()\n",
    "books_encoded_title = books_encoded_title.drop(columns = ['index'])\n",
    "books_encoded_title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'007 El Mundo Nunca Es Suficiente': 0,\n",
       " '4000 Vornamen aus aller Welt. Von Alexander bis Zoe.': 1,\n",
       " \"A Kid's Guide to How to Save the Planet (Camelot world)\": 2,\n",
       " 'A Kiss of Shadows (Meredith Gentry Novels (Paperback))': 3,\n",
       " 'A Painted House': 4,\n",
       " 'A String in the Harp': 5,\n",
       " 'A Wrinkle In Time': 6,\n",
       " 'Adressat unbekannt.': 7,\n",
       " 'Advanced Photography, Sixth Edition': 8,\n",
       " 'Alaska': 9,\n",
       " \"Alice's Adventures in Wonderland and Through the Looking Glass\": 10,\n",
       " 'Alone with the Dead (Joe Keough Mysteries (Paperback))': 11,\n",
       " 'Along Came a Spider (Alex Cross Novels)': 12,\n",
       " 'Alte Freunde, neue Feinde. Ein Fall f�?¼r Bernhard Gunther.': 13,\n",
       " 'Anna Karenina': 14,\n",
       " 'Apricots on the Nile: A Memoir with Recipes': 15,\n",
       " 'Artemis Fowl (Artemis Fowl, Book 1)': 16,\n",
       " 'Artemis Fowl.': 17,\n",
       " 'Asche zu Asche.': 18,\n",
       " 'At the Edge': 19,\n",
       " 'Attack Of The Deranged Mutant Killer Snow Goons': 20,\n",
       " 'Auf Ehre und Gewissen. Roman.': 21,\n",
       " 'Auf der Suche nach dem verlorenen Gl�?¼ck.': 22,\n",
       " 'Auf d�?¼nnem Eis.': 23,\n",
       " \"BD Pirate : Cupidon, tome 2 : Philtre d'amour\": 24,\n",
       " 'BD Pirate : Cupidon, tome 3 : Baiser de feu': 25,\n",
       " \"Back When We Were Grownups : A Novel (Ballantine Reader's Circle)\": 26,\n",
       " 'Battle Angel Alita - Fallen Angel (Battle Angel Alita , No.8)': 27,\n",
       " 'Beim Naechsten Mann Wird Alles (Frau in Der Gesellschaft)': 28,\n",
       " 'Benedict Canyon': 29,\n",
       " 'Besiegt vom Sturm der Leidenschaft.': 30,\n",
       " \"Big Girls Don't Cry\": 31,\n",
       " 'Birdsong: A Novel of Love and War': 32,\n",
       " 'Black Box (Vintage International)': 33,\n",
       " 'Blackwood Farm (Rice, Anne, Vampire Chronicles.)': 34,\n",
       " 'Blooded (Buffy the Vampire Slayer, Book 5)': 35,\n",
       " 'Bloomability': 36,\n",
       " \"Bridget Jones's Diary\": 37,\n",
       " \"Bridget Jones's Diary: Music from the Motion Picture\": 38,\n",
       " 'Bridget Jones:Sobreviviré': 39,\n",
       " 'Briefe der Liebe.': 40,\n",
       " 'Buzon De Tiempo': 41,\n",
       " 'CLOUT': 42,\n",
       " 'Calvin and Hobbes': 43,\n",
       " 'Canone inverso: Romanzo (Scrittori italiani)': 44,\n",
       " 'Change Your Job, Change Your Life: High Impact Strategies for Finding Great Jobs in the Decade Ahead (Change Your Job Change Your Life, 7th ed)': 45,\n",
       " \"Childhood's End\": 46,\n",
       " 'Cinco Semanas En Globo (Espasa Bolsillo)': 47,\n",
       " 'Close to the Bone': 48,\n",
       " 'Close to the Knives': 49,\n",
       " 'Codice: Racconto (Varianti)': 50,\n",
       " \"Comp Murphy's Law\": 51,\n",
       " \"Contes De Ma Mere L'Oye\": 52,\n",
       " 'Crows': 53,\n",
       " 'Cuentos Inconclusos': 54,\n",
       " 'C�?¤sar und Kleopatra. Die letzten Tage der R�?¶mischen Republik.': 55,\n",
       " 'Dark Angel (Casteel)': 56,\n",
       " 'Dark Paradise': 57,\n",
       " 'Das Haus auf den Klippen.': 58,\n",
       " 'Das Lacheln der Fortuna: Historischer Roman': 59,\n",
       " 'Das Schwarze Auge. Aus dunkler Tiefe.': 60,\n",
       " 'Das Superwieb': 61,\n",
       " 'Das bizarre Sexualleben der Tiere. Ein popul�?¤res Lexikon von Aal bis Zebra.': 62,\n",
       " 'Das geheime ABC der Toten.': 63,\n",
       " 'Dear Children of the Earth: A Letter from Home': 64,\n",
       " 'Demon in My View (Laurel-Leaf Books)': 65,\n",
       " 'Denn keiner ist ohne Schuld.': 66,\n",
       " 'Denn sie betr�?¼gt man nicht.': 67,\n",
       " 'Der Bronzeh�?¤ndler.': 68,\n",
       " 'Der Englishche Patient': 69,\n",
       " 'Der Geschichtenverk�?¤ufer.': 70,\n",
       " 'Der Goldene Kompass / The Golden Compass': 71,\n",
       " 'Der Herr der Ringe. Anh�?¤nge und Register.': 72,\n",
       " 'Der Kleine Hobbit': 73,\n",
       " 'Der Regenmacher.': 74,\n",
       " 'Der Spion und die Zauberin.': 75,\n",
       " 'Der Stein der Kelten.': 76,\n",
       " 'Der Sterne Tennisb�?¤lle.': 77,\n",
       " 'Der Tag X.': 78,\n",
       " 'Der Unsichtbare. ( Ab 13 J.).': 79,\n",
       " 'Der Unterh�?¤ndler.': 80,\n",
       " 'Des bateaux dans la nuit': 81,\n",
       " 'Desert Flower : The Extraordinary Journey Of A Desert Nomad': 82,\n",
       " 'Deux Grands Ducs Dans La Famille (Collection Des Deux Solitudes: Jeunesse)': 83,\n",
       " 'Die Benachteiligung erfolgt durch die Post. Stilbl�?¼ten aus Inseraten und Pressenotizen.': 84,\n",
       " 'Die Chirurgin.': 85,\n",
       " 'Die Dinge des Lebens.': 86,\n",
       " 'Die Firma. Roman.': 87,\n",
       " 'Die Gefahrten I': 88,\n",
       " 'Die Hirnk�?¶nigin.': 89,\n",
       " 'Die H�?¤upter meiner Lieben.': 90,\n",
       " 'Die Jury. Roman.': 91,\n",
       " 'Die Krone der Welt.': 92,\n",
       " 'Die Kunst des Verschwindens.': 93,\n",
       " 'Die M�?¤dchen mit den dunklen Augen.': 94,\n",
       " 'Die Scheibenwelt. Zwei Romane in einem Band. Das Licht der Phantasie / Das Erbe des Zauberers.': 95,\n",
       " 'Die St�?¶renfrieds. Geschichten von Leo und Paulina.': 96,\n",
       " 'Die Teufelin. Roman.': 97,\n",
       " 'Die Tochter der W�?¤lder.': 98,\n",
       " 'Die Weiss Lowin / Contemporary German Lit': 99,\n",
       " 'Die Welle': 100,\n",
       " 'Die Wiederkehr Des Konigs III': 101,\n",
       " 'Die Wolfsfrau. Die Kraft der weiblichen Urinstinkte.': 102,\n",
       " 'Die Zauberfrau.': 103,\n",
       " 'Die Zauberin von Ruwenda.': 104,\n",
       " 'Die Zwei Turme II': 105,\n",
       " 'Die rote Antilope.': 106,\n",
       " 'Die siebte Gei�?�?el.': 107,\n",
       " 'Die zweite Haut.': 108,\n",
       " 'Durch Teebaum�?¶l gesund und sch�?¶n.': 109,\n",
       " 'East, West': 110,\n",
       " 'Ein Fall f�?¼r Kay Scarpetta / Ein Mord f�?¼r Kay Scarpetta. Zwei Romane in einem Band.': 111,\n",
       " 'Ein Liebhaber zuviel ist noch zu wenig.': 112,\n",
       " 'Ein Mann f�?¼r jede Tonart. Roman. ( Die Frau in der Gesellschaft).': 113,\n",
       " 'El Diaro De Bridget Jones': 114,\n",
       " 'El Elogio de La Sombra': 115,\n",
       " 'El Perfume: Historia De UN Asesino/Perfume : The Story of a Murderer': 116,\n",
       " 'El Principito': 117,\n",
       " \"Ender's Game (Ender Wiggins Saga (Paperback))\": 118,\n",
       " 'Endlich Nichtraucher.': 119,\n",
       " 'Escarabajos Vuelan Al Atardecer, Los': 120,\n",
       " 'Estação Carandiru': 121,\n",
       " 'False Memory': 122,\n",
       " 'Field of Dishonor (Honor Harrington Series, Book 4)': 123,\n",
       " 'Flesh Tones: A Novel': 124,\n",
       " 'Flight of Eagles': 125,\n",
       " 'Forbidden Forest: The Story of Little John and Robin Hood': 126,\n",
       " 'Frankenstein (Dover Thrift Editions)': 127,\n",
       " 'French Cuisine for All': 128,\n",
       " 'Garzanti - Gli Elefanti: Altre Inquisizioni': 129,\n",
       " 'Gates of Paradise (Casteel)': 130,\n",
       " 'Gevatter Tod. Roman. ( Fantasy).': 131,\n",
       " 'Girl Coming in for a Landing': 132,\n",
       " 'Go Ask Alice (Avon/Flare Book)': 133,\n",
       " 'God Game': 134,\n",
       " \"Going Inside: A Couple's Journey of Renewal into the North\": 135,\n",
       " 'Goldmann: Feuer in Berlin': 136,\n",
       " 'Gratsch.': 137,\n",
       " 'Great British Ghosts (Longman Structural Readers: Background)': 138,\n",
       " 'Growing Wings': 139,\n",
       " 'Harold and the Purple Crayon 50th Anniversary Edition (Purple Crayon Books)': 140,\n",
       " 'Harry Potter Schoolbooks: Quidditch Through the Ages and Fantastic Beasts and Where to Find Them': 141,\n",
       " 'Harry Potter Und Der Feuerkelch': 142,\n",
       " 'Harry Potter and the Order of the Phoenix (Book 5)': 143,\n",
       " 'Harry Potter and the Prisoner of Azkaban': 144,\n",
       " \"Harry Potter and the Sorcerer's Stone Movie Poster Book\": 145,\n",
       " 'Harry Potter und der Gefangene von Azkaban': 146,\n",
       " 'Harry Potter und der Stein der Weisen': 147,\n",
       " 'Harry Potter und die Kammer des Schreckens': 148,\n",
       " 'Hasenherz. Roman.': 149,\n",
       " 'Help!: Level 1': 150,\n",
       " 'Henry der Held.': 151,\n",
       " 'High Stakes': 152,\n",
       " 'Hitlers Kinder.': 153,\n",
       " 'Hoot (Newbery Honor Book)': 154,\n",
       " 'House of the Sun (Shadowrun)': 155,\n",
       " 'How Stella Got Her Groove Back': 156,\n",
       " 'How To Win Friends And Influence People': 157,\n",
       " 'How to Deal With Difficult People': 158,\n",
       " 'How to Deal With Your Parents: When They Still Treat You Like a Child': 159,\n",
       " 'Ice Blade: Snow Country (Ice Blade)': 160,\n",
       " 'Ich liebe Dich!: Ein Eisenbahnroman mit 66 Intermezzos': 161,\n",
       " 'Ich, Prinzessin aus dem Hause Al Saud. Ein Leben hinter tausend Schleiern.': 162,\n",
       " 'Il birraio di Preston (La memoria)': 163,\n",
       " 'Im Angesicht des Feindes.': 164,\n",
       " 'Im Eishaus.': 165,\n",
       " 'Im Fr�?¼hling singt zum letztenmal die Lerche.': 166,\n",
       " 'Im Keller.': 167,\n",
       " 'Im Netz der Spinnen. Videokill.': 168,\n",
       " 'Im Schatten der Lilie. Die Erinnerungen der Eleonore von Aquitanien.': 169,\n",
       " 'In Cold Blood (Vintage International)': 170,\n",
       " 'Inspektor Jury bricht das Eis. Roman.': 171,\n",
       " 'Inspektor Jury k�?¼�?�?t die Muse. Roman.': 172,\n",
       " 'Invitacion a la Etica': 173,\n",
       " 'Isabelle Eberhardt': 174,\n",
       " \"Iznogoud, tome 2 : Les complots d'Iznogoud\": 175,\n",
       " 'Jane Eyre (Dover Thrift Editions)': 176,\n",
       " 'Jean-Edern Hallier': 177,\n",
       " 'Journey Through Nature (Journey Through Series)': 178,\n",
       " 'Kaltgestellt.': 179,\n",
       " 'Katie.com': 180,\n",
       " 'Keiner werfe den ersten Stein. Roman.': 181,\n",
       " 'Kim (Puffin Classics-the Essential Collection)': 182,\n",
       " \"King Solomon's Mines (Tor Classics)\": 183,\n",
       " \"L'Appel de la for�?ªt\": 184,\n",
       " \"L'Orage\": 185,\n",
       " 'La Citadelle Du Vertige': 186,\n",
       " 'La Fiesta De Ralph': 187,\n",
       " 'La Testa Fra Le Nuvole': 188,\n",
       " 'La casa de los espíritus': 189,\n",
       " 'La hija del Caníbal': 190,\n",
       " 'La petite �?©cuy�?¨re a caft�?©': 191,\n",
       " 'Le Grand Meaulnes (Classiques De Poche)': 192,\n",
       " \"Le Parfum : Histoire d'un meurtrier\": 193,\n",
       " 'Le Petit Prince. (Franz�?¶sische Ausgabe). (Lernmaterialien)': 194,\n",
       " 'Le chateau des carpathes': 195,\n",
       " 'Les Confessions: Livres I �?\\xa0 IV': 196,\n",
       " 'Les Particules Elementaires': 197,\n",
       " 'Les Six Compagnons �?\\xa0 Scotland Yard': 198,\n",
       " \"Les Tuniques bleues, tome 1 : un chariot dans l'ouest\": 199,\n",
       " 'Les derniers g�?©ants': 200,\n",
       " \"Les derniers po�?¨mes d'amour\": 201,\n",
       " 'Lieber Sport als Mord.': 202,\n",
       " 'Lightning': 203,\n",
       " 'Little Altars Everywhere': 204,\n",
       " 'Live aus Bagdad. Das Tagebuch einer Kriegs-Reporterin.': 205,\n",
       " 'Los Calusari/the Calusari (Coleccion \\\\\"Expediente X\\\\\"/the X Files Series)': 206,\n",
       " 'Los Trapos Sucios - Manolito Gafotas': 207,\n",
       " 'Love Story': 208,\n",
       " \"Love in the Time of Cholera (Everyman's Library (Cloth))\": 209,\n",
       " 'L�?©onard, tome 1 : L�?©onard est un g�?©nie': 210,\n",
       " 'Make Them Cry': 211,\n",
       " 'Manhattan Hunt Club': 212,\n",
       " 'Matilda': 213,\n",
       " 'Maudit Manege': 214,\n",
       " 'Mit dem K�?¼hlschrank durch Irland.': 215,\n",
       " 'Moby Dick (Coleccion)': 216,\n",
       " 'Moby Dick. ( Ab 12 J.).': 217,\n",
       " 'Mon bel oranger': 218,\n",
       " 'Moon Handbooks: Hawaii': 219,\n",
       " 'Move to Strike': 220,\n",
       " 'Murder at the Margin': 221,\n",
       " 'My \\\\\"Star Trek\\\\\" Memories': 222,\n",
       " 'Mycroft Holmes Contra La Hermandad': 223,\n",
       " 'Nachtschicht.': 224,\n",
       " 'Nadie Es Perfecto (Narrativa Actual)': 225,\n",
       " 'Night Sins': 226,\n",
       " 'Nomadentochter.': 227,\n",
       " 'Nordermoor': 228,\n",
       " 'Nur der Tod ist ohne Makel.': 229,\n",
       " 'O Pioneers! (Bantam Classic)': 230,\n",
       " 'Oceano Mare': 231,\n",
       " 'Of Mice and Men. Text and Study Aids. (Lernmaterialien)': 232,\n",
       " 'One': 233,\n",
       " \"One Flew over the Cuckoo's Nest (Penguin Classics)\": 234,\n",
       " 'One Thousand Chestnut Trees': 235,\n",
       " 'Overnight (Fear Street) : Overnight (Fear Street Series)': 236,\n",
       " 'PERFUME : PERFUME': 237,\n",
       " 'Pay Dirt (Mrs. Murphy Mysteries (Paperback))': 238,\n",
       " \"Percevan, tome 1 : Les Trois Etoiles d'Ingaar\": 239,\n",
       " 'Piccoli Equivoci Senza Importanza: Piccoli Equivoci Senza Importanza': 240,\n",
       " 'Politically Correct Bedtime Stories: Modern Tales for Our Life and Times': 241,\n",
       " 'Por los pelos': 242,\n",
       " 'Prinz der Kelche.': 243,\n",
       " 'Q': 244,\n",
       " 'Quidditch Through the Ages': 245,\n",
       " 'Rabbit in Ruhe.': 246,\n",
       " 'Rand.': 247,\n",
       " 'Random Acts of Kindness': 248,\n",
       " 'Reif f�?¼r die Insel. England f�?¼r Anf�?¤nger und Fortgeschrittene.': 249,\n",
       " 'Reise nach Ixtlan. Die Lehre des Don Juan.': 250,\n",
       " 'Richard Brautigan : A Confederate General from Big Sur, Dreaming of Babylon, and the Hawkline Monster (Three Books in the Manner of Their Original ed)': 251,\n",
       " 'Rites of Passage': 252,\n",
       " 'Roan (Blake, Jennifer, Louisiana Gentlemen Series.)': 253,\n",
       " 'Round about Midnight: A Portrait of Miles Davis': 254,\n",
       " 'Saemtliche Erzaehlungen': 255,\n",
       " 'Saving Private Ryan': 256,\n",
       " 'Schlafes Bruder': 257,\n",
       " 'See Jane Run': 258,\n",
       " 'Shadowland': 259,\n",
       " 'Siddharta Romanzo Versione Di M Mila': 260,\n",
       " 'Skin and Other Stories (Now in Speak!)': 261,\n",
       " 'Soul Survivor': 262,\n",
       " 'Southampton Row (Charlotte &amp': 263,\n",
       " 'Speaking in Tongues': 264,\n",
       " 'Storm Surge: A Quin St. James and Mike McCleary Mystery': 265,\n",
       " 'Stupeur Et Tremblements': 266,\n",
       " 'Sturm der Liebe.': 267,\n",
       " 'Surviving Sam': 268,\n",
       " 'Sushi for Beginners : A Novel (Keyes, Marian)': 269,\n",
       " 'Tales of the Greek Heroes: Retold from the Ancient Authors (Puffin Classics)': 270,\n",
       " 'The Amsterdam Connection : Level 4 (Cambridge English Readers)': 271,\n",
       " \"The Best of Bombeck: At Wit's End, Just Wait Until You Have Children of Your Own, I Lost Everything in the Post-Natal Depression\": 272,\n",
       " 'The Boy Next Door': 273,\n",
       " 'The Circle And The Cross 1: Playing Of': 274,\n",
       " \"The Complete Idiot's Guide to the Microsoft Network\": 275,\n",
       " 'The Complete Idiots Guide to Getting the Job You Want (W/2 Discs)': 276,\n",
       " 'The Contest': 277,\n",
       " 'The Coral Island (Puffin Classics)': 278,\n",
       " 'The Da Vinci Code': 279,\n",
       " 'The Dark Half': 280,\n",
       " 'The Girl Who Loved Tom Gordon : A Novel': 281,\n",
       " 'The Golden Rule of Schmoozing': 282,\n",
       " 'The Holiday Present': 283,\n",
       " 'The Jester': 284,\n",
       " 'The Joy Luck Club': 285,\n",
       " 'The Keys to the Street': 286,\n",
       " 'The King of Torts': 287,\n",
       " 'The Last Book in the Universe': 288,\n",
       " 'The Last Time They Met : A Novel': 289,\n",
       " 'The Law of Love': 290,\n",
       " 'The Lovely Bones: A Novel': 291,\n",
       " 'The MouseDriver Chronicles': 292,\n",
       " 'The Music of Chance': 293,\n",
       " 'The Name of the Rose': 294,\n",
       " 'The Notebook': 295,\n",
       " 'The Number Devil: A Mathematical Adventure': 296,\n",
       " 'The Picture of Dorian Gray': 297,\n",
       " 'The Pillars of the Earth': 298,\n",
       " 'The Power to Harm: Mind, Medicine, and Murder on Trial': 299,\n",
       " 'The Rebel Angels': 300,\n",
       " \"The Restaurant at the End of the Universe (Hitchhiker's Trilogy (Paperback))\": 301,\n",
       " 'The Riddle of Scheherazade: And Other Amazing Puzzles': 302,\n",
       " 'The Sandy Bottom Orchestra': 303,\n",
       " 'The Second Summer of the Sisterhood': 304,\n",
       " \"The Strange Case of Dr. Jekyll and Mr. Hyde and Weir of Hermiston: And, Weir of Hermiston (Oxford World's Classics)\": 305,\n",
       " 'The Tower at Stony Wood': 306,\n",
       " 'The Watsons Go to Birmingham - 1963 (Yearling Newbery)': 307,\n",
       " 'The Wonderful Story of Henry Sugar and Six More': 308,\n",
       " 'The X-Files: Goblins': 309,\n",
       " 'The X-Files: Ground Zero': 310,\n",
       " 'The Year of Sharing (Oxford Bookworms)': 311,\n",
       " 'Tod im wei�?�?en H�?¤ubchen.': 312,\n",
       " \"Tom Clancy's Op- Center. Spiegelbild.\": 313,\n",
       " 'Toxin': 314,\n",
       " 'Ubu Roi*': 315,\n",
       " \"Un Amore Dell'altro Mondo\": 316,\n",
       " 'Un Bon Petit Diable': 317,\n",
       " \"Un Giorno Dopo L'altro\": 318,\n",
       " 'Undank ist der V�?¤ter Lohn.': 319,\n",
       " 'Ungarn.': 320,\n",
       " 'Uther (Camulod Chronicles)': 321,\n",
       " 'Vater Himmel, Mutter Erde.': 322,\n",
       " 'Verraten und verkauft. Roman.': 323,\n",
       " 'Vieja Nueva York': 324,\n",
       " 'Waiting for Godot': 325,\n",
       " 'Waiting to Exhale': 326,\n",
       " 'Walk Two Moons': 327,\n",
       " 'Was Mir Wichtig War: Letzte Aufzeichnungen Und Gesprache': 328,\n",
       " 'Wasted : A Memoir of Anorexia and Bulimia': 329,\n",
       " \"What's That Pig Outdoors: A Memoir of Deafness\": 330,\n",
       " 'Whirlwind (The X-Files)': 331,\n",
       " 'Whispers': 332,\n",
       " 'Wild Animus': 333,\n",
       " 'Wilt: Tom Sharpe': 334,\n",
       " '¡No bajes al sótano! (Escalofríos No. 2)': 335}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mapper from book title to index\n",
    "# book: index\n",
    "book_to_idx = {\n",
    "    book: i for i, book in enumerate(list(books_encoded_title.set_index('BookID_Encoded').loc[books_matrix.index].BookTitle))\n",
    "}\n",
    "book_to_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils import\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def fuzzy_matching(mapper, fav_book, verbose=True):\n",
    "    \"\"\"\n",
    "    return the closest match via fuzzy ratio. If no match found, return None\n",
    "    \n",
    "    Parameters\n",
    "    ----------    \n",
    "    mapper: dict, map book title name to index of the book in data\n",
    "\n",
    "    fav_book: str, name of user input book\n",
    "    \n",
    "    verbose: bool, print log if True\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    index of the closest match\n",
    "    \"\"\"\n",
    "    match_tuple = []\n",
    "    # get match\n",
    "    for title, idx in mapper.items():\n",
    "        ratio = fuzz.ratio(title.lower(), fav_book.lower())\n",
    "        if ratio >= 60:\n",
    "            match_tuple.append((title, idx, ratio))\n",
    "            \n",
    "    # sort\n",
    "    match_tuple = sorted(match_tuple, key=lambda x: x[2])[::-1]\n",
    "    if not match_tuple:\n",
    "        print('Oops! No match is found')\n",
    "        return\n",
    "    if verbose:\n",
    "        print('Found possible matches in our database: {0}\\n'.format([x[0] for x in match_tuple]))\n",
    "    return match_tuple[0][1]\n",
    "\n",
    "\n",
    "\n",
    "def make_recommendation(model_knn, data, mapper, fav_book, n_recommendations):\n",
    "    \"\"\"\n",
    "    return top n similar book recommendations based on user's input book\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_knn: sklearn model, knn model\n",
    "\n",
    "    data: book-user matrix\n",
    "\n",
    "    mapper: dict, map book title name to index of the book in data\n",
    "\n",
    "    fav_book: str, name of user input book\n",
    "\n",
    "    n_recommendations: int, top n recommendations\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    list of top n similar book recommendations\n",
    "    \"\"\"\n",
    "    # fit\n",
    "    model_knn.fit(data)\n",
    "    \n",
    "    # get input book index\n",
    "    print('You have input book:', fav_book)\n",
    "    idx = fuzzy_matching(mapper, fav_book, verbose=True)\n",
    "    \n",
    "    # inference\n",
    "    print('Recommendation system start to make inference')\n",
    "    print('......\\n')\n",
    "    distances, indices = model_knn.kneighbors(data[idx], n_neighbors=n_recommendations+1)\n",
    "    # get list of raw idx of recommendations\n",
    "    raw_recommends = \\\n",
    "        sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    # get reverse mapper\n",
    "    reverse_mapper = {v: k for k, v in mapper.items()}\n",
    "    # print recommendations\n",
    "    print('Recommendations for {}:'.format(fav_book))\n",
    "    for i, (idx, dist) in reversed(list(enumerate(raw_recommends))):\n",
    "        #j =i\n",
    "        print('{0}: {1}, with distance of {2}'.format(n_recommendations-i, reverse_mapper[idx], dist))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_favorite = 'Harry Potter and the Order of the Phoenix (Book 5)'\n",
    "# my_favorite = 'Harry Potter and the Prisoner of Azkaban'\n",
    "# my_favorite = 'How To Win Friends And Influence People'\n",
    "# my_favorite = 'Sushi for Beginners : A Novel (Keyes, Marian)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have input book: Harry Potter and the Order of the Phoenix (Book 5)\n",
      "Found possible matches in our database: ['Harry Potter and the Order of the Phoenix (Book 5)', \"Harry Potter and the Sorcerer's Stone Movie Poster Book\", 'Harry Potter and the Prisoner of Azkaban', 'Harry Potter und der Stein der Weisen']\n",
      "\n",
      "Recommendation system start to make inference\n",
      "......\n",
      "\n",
      "Recommendations for Harry Potter and the Order of the Phoenix (Book 5):\n",
      "1: Moon Handbooks: Hawaii, with distance of 0.9281630286084136\n",
      "2: A Wrinkle In Time, with distance of 0.9367295186553608\n",
      "3: The Second Summer of the Sisterhood, with distance of 0.9397670038835066\n",
      "4: The Da Vinci Code, with distance of 0.9401336850106279\n",
      "5: Quidditch Through the Ages, with distance of 0.9412078850185526\n"
     ]
    }
   ],
   "source": [
    "#TODO - check why the result with different model is exactly same\n",
    "\n",
    "# Recommendation based on KNN model 1\n",
    "make_recommendation(\n",
    "    model_knn=model_knn_1, # trained model (model)\n",
    "    data=books_matrix_sparse, # sparse matrix (data)\n",
    "    fav_book=my_favorite, # fav_book\n",
    "    mapper=book_to_idx, # {book: index} (mapper)\n",
    "    n_recommendations=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have input book: Harry Potter and the Order of the Phoenix (Book 5)\n",
      "Found possible matches in our database: ['Harry Potter and the Order of the Phoenix (Book 5)', \"Harry Potter and the Sorcerer's Stone Movie Poster Book\", 'Harry Potter and the Prisoner of Azkaban', 'Harry Potter und der Stein der Weisen']\n",
      "\n",
      "Recommendation system start to make inference\n",
      "......\n",
      "\n",
      "Recommendations for Harry Potter and the Order of the Phoenix (Book 5):\n",
      "1: Moon Handbooks: Hawaii, with distance of 0.9281630286084136\n",
      "2: A Wrinkle In Time, with distance of 0.9367295186553608\n",
      "3: The Second Summer of the Sisterhood, with distance of 0.9397670038835066\n",
      "4: The Da Vinci Code, with distance of 0.9401336850106279\n",
      "5: Quidditch Through the Ages, with distance of 0.9412078850185526\n"
     ]
    }
   ],
   "source": [
    "# Recommendation based on KNN model 2\n",
    "make_recommendation(\n",
    "    model_knn=model_knn_2, # trained model (model)\n",
    "    data=books_matrix_sparse, # sparse matrix (data)\n",
    "    fav_book=my_favorite, # fav_book\n",
    "    mapper=book_to_idx, # {book: index} (mapper)\n",
    "    n_recommendations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCJz_Do9Yb5q"
   },
   "source": [
    "**2.4 Discuss the results you received in both cases. Would you like to read some of the recommended books? Out of 2 or 10 neighbors, which one worked better? (There is no right or wrong answer in this question) (0.25 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CdPc75QYb5r"
   },
   "source": [
    "<font color='red'> **Answer:**</font>\n",
    "\n",
    "- I would like to read The Da Vinci Code and Quidditch Through the Ages, but not the other books\n",
    "- It give the exact same result with same distance value, so both of models works in same way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G6T3K3VFYb5s"
   },
   "source": [
    "**2.5 Add a new user (with user “UserID” = 6293) in your data. Using the two trained models in task 2.3 suggest which books should this user read if his ratings are:**\n",
    "\n",
    "French Cuisine for All: 4\n",
    "\n",
    "\n",
    "Harry Potter and the Sorcerer's Stone Movie Poster Book: 5\n",
    "\n",
    "\n",
    "El Perfume: Historia De UN Asesino/Perfume : The Story of a Murderer: 1\n",
    "\n",
    "**(1. 25 points)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-EJOEy1Yb5t"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookID_Encoded</th>\n",
       "      <th>BookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>128</td>\n",
       "      <td>French Cuisine for All</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BookID_Encoded               BookTitle\n",
       "214             128  French Cuisine for All"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_encoded_title[books_encoded_title['BookTitle'] == 'French Cuisine for All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookID_Encoded</th>\n",
       "      <th>BookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>145</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone Movie Po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BookID_Encoded                                          BookTitle\n",
       "311             145  Harry Potter and the Sorcerer's Stone Movie Po..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_encoded_title[books_encoded_title['BookTitle'] == \"Harry Potter and the Sorcerer's Stone Movie Poster Book\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BookID_Encoded</th>\n",
       "      <th>BookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>116</td>\n",
       "      <td>El Perfume: Historia De UN Asesino/Perfume : T...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BookID_Encoded                                          BookTitle\n",
       "289             116  El Perfume: Historia De UN Asesino/Perfume : T..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_encoded_title[books_encoded_title['BookTitle'] == \"El Perfume: Historia De UN Asesino/Perfume : The Story of a Murderer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>BookID_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6293</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6293</td>\n",
       "      <td>5</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6293</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  Book-Rating  BookID_Encoded\n",
       "0    6293            4             128\n",
       "1    6293            5             145\n",
       "2    6293            1             116"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.DataFrame({\"UserID\":[6293, 6293, 6293], \n",
    "                       \"Book-Rating\":[4, 5, 1], \n",
    "                       \"BookID_Encoded\":[128, 145, 116]})\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>BookID_Encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3668</td>\n",
       "      <td>9</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3670</td>\n",
       "      <td>0</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>6293</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>6293</td>\n",
       "      <td>5</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>6293</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       UserID  Book-Rating  BookID_Encoded\n",
       "9996     3668            9             333\n",
       "9997     3670            0             333\n",
       "9998     6293            4             128\n",
       "9999     6293            5             145\n",
       "10000    6293            1             116"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_encoded_no_dup_new = books_encoded_no_dup.append(new_df)\n",
    "books_encoded_no_dup_new = books_encoded_no_dup_new.reset_index()\n",
    "books_encoded_no_dup_new = books_encoded_no_dup_new.drop(columns = ['index'])\n",
    "books_encoded_no_dup_new.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_matrix_new = books_encoded_no_dup_new.pivot(index = 'BookID_Encoded', columns = 'UserID', values = 'Book-Rating').fillna(0)\n",
    "books_matrix_sparse_new = csr_matrix(books_matrix_new.values)\n",
    "# print(f\"Sparse matrix:\\n{books_matrix_sparse_new}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_favorite = \"Harry Potter and the Sorcerer's Stone Movie Poster Book\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have input book: Harry Potter and the Sorcerer's Stone Movie Poster Book\n",
      "Found possible matches in our database: [\"Harry Potter and the Sorcerer's Stone Movie Poster Book\", 'Harry Potter and the Order of the Phoenix (Book 5)', 'Harry Potter and the Prisoner of Azkaban']\n",
      "\n",
      "Recommendation system start to make inference\n",
      "......\n",
      "\n",
      "Recommendations for Harry Potter and the Sorcerer's Stone Movie Poster Book:\n",
      "1: Nadie Es Perfecto (Narrativa Actual), with distance of 1.0\n",
      "2: Nomadentochter., with distance of 1.0\n",
      "3: Nachtschicht., with distance of 1.0\n",
      "4: My \\\"Star Trek\\\" Memories, with distance of 1.0\n",
      "5: Night Sins, with distance of 1.0\n"
     ]
    }
   ],
   "source": [
    "# Recommendation based on KNN model 1\n",
    "make_recommendation(\n",
    "    model_knn=model_knn_1, # trained model (model)\n",
    "    data=books_matrix_sparse, # sparse matrix (data)\n",
    "    fav_book=my_favorite, # fav_book\n",
    "    mapper=book_to_idx, # {book: index} (mapper)\n",
    "    n_recommendations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have input book: Harry Potter and the Sorcerer's Stone Movie Poster Book\n",
      "Found possible matches in our database: [\"Harry Potter and the Sorcerer's Stone Movie Poster Book\", 'Harry Potter and the Order of the Phoenix (Book 5)', 'Harry Potter and the Prisoner of Azkaban']\n",
      "\n",
      "Recommendation system start to make inference\n",
      "......\n",
      "\n",
      "Recommendations for Harry Potter and the Sorcerer's Stone Movie Poster Book:\n",
      "1: French Cuisine for All, with distance of 0.7974521265832667\n",
      "2: El Perfume: Historia De UN Asesino/Perfume : The Story of a Murderer, with distance of 0.97756064455674\n",
      "3: Matilda, with distance of 1.0\n",
      "4: Night Sins, with distance of 1.0\n",
      "5: Nadie Es Perfecto (Narrativa Actual), with distance of 1.0\n"
     ]
    }
   ],
   "source": [
    "# Recommendation based on KNN model 2\n",
    "make_recommendation(\n",
    "    model_knn=model_knn_2, # trained model (model)\n",
    "    data=books_matrix_sparse_new, # sparse matrix (data)\n",
    "    fav_book=my_favorite, # fav_book\n",
    "    mapper=book_to_idx, # {book: index} (mapper)\n",
    "    n_recommendations=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Book suggestion for **UserID” = 6293** are:\n",
    "\n",
    "1. Nadie Es Perfecto (Narrativa Actual), with distance of 1.0\n",
    "2. Nomadentochter., with distance of 1.0\n",
    "3. Nachtschicht., with distance of 1.0\n",
    "4. My \\\"Star Trek\\\" Memories, with distance of 1.0\n",
    "5. Night Sins, with distance of 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMyW4UlbYb5x"
   },
   "source": [
    "# 3. Recommender systems evaluation (1.5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EINSDAbXYb5y"
   },
   "source": [
    "We are going to compare different methods of recommender systems by their RMSE score. One useful package that has several recommender algorithms for Python is [Surprise](https://surprise.readthedocs.io/en/stable/getting_started.html). Below we have split the books dataset into training and test and used the KNNBasic algorithm to predict the ratings for the test set using surprise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OoLm-EC1Yb5z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 4.1033\n",
      "KNN RMSE 4.10333158257073\n"
     ]
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "\n",
    "# The reader is necessary for surprise to interpret the ratings\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "\n",
    "# This function loads data from a pandas dataframe into surprise dataset structure\n",
    "# The columns should always be ordered like this\n",
    "# data = Dataset.load_from_df(df[['UserID', 'BookTitle', 'Book-Rating']], reader)\n",
    "data = Dataset.load_from_df(books[['UserID', 'BookTitle', 'Book-Rating']], reader)\n",
    "\n",
    "# Split in trainset and testset\n",
    "# No need to define the label y because for surprise the last column is always the rating\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0 )\n",
    "\n",
    "knn = KNNBasic()\n",
    "knn.fit(trainset)\n",
    "predictions = knn.test(testset)\n",
    "print('KNN RMSE', accuracy.rmse(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sdIaAghiYb53"
   },
   "source": [
    "**3.1 After taking a look at surprise documentation and the code above, follow the same steps as with KNN, and predict the ratings in test set using the NormalPredictor which predicts a random rating based on the distribution of the training set. Do the same for SVD which  is a matrix factorization technique. For both of them report RMSE. (We already have imported the functions for you)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWcalcl4Yb56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.1163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.116258158363693"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np_result = cross_validate(NormalPredictor(), data, measures=['RMSE'], cv=2, verbose=True)\n",
    "\n",
    "npred = NormalPredictor()\n",
    "npred.fit(trainset)\n",
    "pred_npred = npred.test(testset)\n",
    "accuracy.rmse(pred_npred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.8635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.8635017173181803"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "pred_SVD = svd.test(testset)\n",
    "accuracy.rmse(pred_SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>3.861349</td>\n",
       "      <td>0.651670</td>\n",
       "      <td>0.045196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>4.108172</td>\n",
       "      <td>1.302408</td>\n",
       "      <td>0.494330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>5.161092</td>\n",
       "      <td>0.017022</td>\n",
       "      <td>0.060407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  fit_time  test_time\n",
       "Algorithm                                      \n",
       "SVD               3.861349  0.651670   0.045196\n",
       "KNNBasic          4.108172  1.302408   0.494330\n",
       "NormalPredictor   5.161092  0.017022   0.060407"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Do benchmarking between KNNBasic, NormalPredictor, and SVD\n",
    "# Reference:\n",
    "# https://towardsdatascience.com/building-and-testing-recommender-systems-with-surprise-step-by-step-d4ba702ef80b\n",
    "\n",
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "for algorithm in [KNNBasic(), NormalPredictor(), SVD(), ]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    \n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OjJgAOSRYb6A"
   },
   "source": [
    "# 4. Neural Networks (3 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h5TF1ePBYb6L"
   },
   "source": [
    "**4.1 We are now going to build a recommender system using Neural Networks. Being this dataset is really small in terms of features you might not see great improvements but it is a good starting point to learn. Please build  exactly the same neural network as we did in practice session part 3, which had the following layers:**\n",
    "- 2 Embedding\n",
    "- 2 Reshape\n",
    "- 1 Dense\n",
    "\n",
    "**Use the Neural Network you built to learn from the train data of part 3 of this homework.  The column UserID should be used as input to your NN for the user embedding layer. For the books embedding layer we will use BookTitle column. Lastly, the ratings will be your target variable. Regarding the evaluation metric for the training phase use RMSE. To make your training fast you can use a batch size of 200 or above. (1.75 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PbuvaC1eYb6Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense, Multiply, Concatenate, Dropout, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6293\n"
     ]
    }
   ],
   "source": [
    "print(books_encoded_no_dup_new['UserID'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6293, 336, 0, 10)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = books_encoded_no_dup_new['UserID'].nunique()\n",
    "n_books = books_encoded_no_dup_new['BookID_Encoded'].nunique()\n",
    "min_rating = min(books_encoded_no_dup_new['Book-Rating'])\n",
    "max_rating = max(books_encoded_no_dup_new['Book-Rating'])\n",
    "\n",
    "n_users, n_books, min_rating, max_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_encoded_no_dup_new = books_encoded_no_dup_new.reindex(columns=['UserID', 'BookID_Encoded', 'Book-Rating'])\n",
    "# books_encoded_no_dup_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9000, 2), (1001, 2), (9000,), (1001,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = books_encoded_no_dup_new[['UserID', 'BookID_Encoded']].values\n",
    "y = books_encoded_no_dup_new['Book-Rating'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 50\n",
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using only embeddings, same as previous lab session\n",
    "def RecommenderV1(n_users, n_books, n_factors):\n",
    "    user = Input(shape=(1,))\n",
    "    \n",
    "    ## n_users should be added + 1 to resolve InvalidArgumentError: indices[x,x] = xxxx is not in [0, xxxx)\n",
    "    u = Embedding(n_users+1, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=l2(1e-6))(user)\n",
    "    u = Reshape((n_factors,))(u)\n",
    "    \n",
    "    book = Input(shape=(1,))\n",
    "    m = Embedding(n_books, n_factors, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=l2(1e-6))(book)\n",
    "    m = Reshape((n_factors,))(m)\n",
    "    \n",
    "    x = Dot(axes=1)([u, m])   \n",
    "    model = Model(inputs=[user, book], outputs=x)\n",
    "    opt = Adam(lr=0.001)\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_fit_plot(model,num):\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "    # Set batch_size to 200 or more, to make training process faster\n",
    "    history = model.fit(x=X_train_array, y=y_train, batch_size=200, epochs=30,\n",
    "                        verbose=1, validation_data=(X_test_array, y_test))\n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "    plt.plot(history.history['mse'])\n",
    "    plt.plot(history.history['val_mse'])\n",
    "    plt.title('Model MSE')\n",
    "    plt.ylabel('mean_squared_error')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    import math\n",
    "    # Show the best validation RMSE\n",
    "    min_val_loss, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
    "    print(f\"\\nModel: {num},\\nMinimum RMSE at epoch: {idx+1} = {math.sqrt(min_val_loss)}\")\n",
    "    #print ('\\nModel: {:d}\\n'.format(num),'Minimum RMSE at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(math.sqrt(min_val_loss)))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def predict_recommend(model,test_user ):\n",
    "    \n",
    "        # Function to predict the ratings given User ID and Book ID\n",
    "    def predict_rating1(user_id, item_id):\n",
    "        return model.predict([np.array([user_id-1]), np.array([item_id-1])])[0][0]\n",
    "    \n",
    "    # Function to predict the ratings given User ID and Book ID\n",
    "    def predict_rating2(user_id, item_id):        \n",
    "        if item_id<=336:\n",
    "            prediction = model.predict([np.array([user_id-1]), np.array([item_id])])[0][0]\n",
    "            return prediction\n",
    "        \n",
    "    TEST_USER = test_user # A random test user (user_id = 2000)\n",
    "\n",
    "\n",
    "    user_ratings = books_encoded_no_dup_new[books_encoded_no_dup_new['UserID'] == TEST_USER][['UserID', 'BookID_Encoded', 'Book-Rating']]\n",
    "\n",
    "    user_ratings['prediction'] = user_ratings.apply(lambda x: predict_rating1(TEST_USER, x['BookID_Encoded']), axis=1)\n",
    "    user_ratings.sort_values(by='Book-Rating', \n",
    "                             ascending=False).merge(books_encoded_title, \n",
    "                                                    on='BookID_Encoded', \n",
    "                                                    how='inner', \n",
    "                                                    suffixes=['_u', '_m']).head(20)\n",
    "    \n",
    "    recommendations = books_encoded_no_dup_new[books_encoded_no_dup_new['BookID_Encoded'].isin(user_ratings['BookID_Encoded']) == False][['BookID_Encoded']].drop_duplicates()\n",
    "    recommendations['prediction'] = recommendations.apply(lambda x: predict_rating2(TEST_USER, x['BookID_Encoded']), axis=1)\n",
    "    recommendations.sort_values(by='prediction',\n",
    "                              ascending=False).merge(books_encoded_title,\n",
    "                                                     on='BookID_Encoded',\n",
    "                                                     how='inner',\n",
    "                                                     suffixes=['_u', '_m']).head(20)\n",
    "    \n",
    "    return user_ratings, recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_57 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_57 (Embedding)        (None, 1, 50)        314700      input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_58 (Embedding)        (None, 1, 50)        16800       input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_57 (Reshape)            (None, 50)           0           embedding_57[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_58 (Reshape)            (None, 50)           0           embedding_58[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_29 (Dot)                    (None, 1)            0           reshape_57[0][0]                 \n",
      "                                                                 reshape_58[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 331,500\n",
      "Trainable params: 331,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1001 samples\n",
      "Epoch 1/30\n",
      "9000/9000 [==============================] - 1s 60us/step - loss: 27.6701 - mse: 27.6699 - val_loss: 27.3858 - val_mse: 27.3856\n",
      "Epoch 2/30\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 27.5386 - mse: 27.5384 - val_loss: 27.3857 - val_mse: 27.3855\n",
      "Epoch 3/30\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 27.3101 - mse: 27.3099 - val_loss: 27.3860 - val_mse: 27.3857\n",
      "Epoch 4/30\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 26.8788 - mse: 26.8786 - val_loss: 27.3863 - val_mse: 27.3860\n",
      "Epoch 5/30\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 26.1774 - mse: 26.1770 - val_loss: 27.3901 - val_mse: 27.3896\n",
      "Epoch 6/30\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 25.1820 - mse: 25.1815 - val_loss: 27.3914 - val_mse: 27.3908\n",
      "Epoch 7/30\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 23.9158 - mse: 23.9151 - val_loss: 27.3964 - val_mse: 27.3955\n",
      "Epoch 8/30\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 22.4242 - mse: 22.4232 - val_loss: 27.3959 - val_mse: 27.3947\n",
      "Epoch 9/30\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 20.7513 - mse: 20.7500 - val_loss: 27.4086 - val_mse: 27.4071\n",
      "Epoch 10/30\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 18.9731 - mse: 18.9715 - val_loss: 27.4108 - val_mse: 27.4089\n",
      "Epoch 11/30\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 17.1475 - mse: 17.1454 - val_loss: 27.4259 - val_mse: 27.4236\n",
      "Epoch 12/30\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 15.3332 - mse: 15.3307 - val_loss: 27.4341 - val_mse: 27.4314\n",
      "Epoch 13/30\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 13.5797 - mse: 13.5768 - val_loss: 27.4491 - val_mse: 27.4459\n",
      "Epoch 14/30\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 11.9294 - mse: 11.9261 - val_loss: 27.4569 - val_mse: 27.4534\n",
      "Epoch 15/30\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 10.4213 - mse: 10.4175 - val_loss: 27.4720 - val_mse: 27.4679\n",
      "Epoch 16/30\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 9.0532 - mse: 9.0490 - val_loss: 27.4831 - val_mse: 27.4786\n",
      "Epoch 17/30\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 7.8475 - mse: 7.8429 - val_loss: 27.4881 - val_mse: 27.4831\n",
      "Epoch 18/30\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 6.7956 - mse: 6.7905 - val_loss: 27.4998 - val_mse: 27.4945\n",
      "Epoch 19/30\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 5.8842 - mse: 5.8787 - val_loss: 27.5083 - val_mse: 27.5025\n",
      "Epoch 20/30\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 5.1041 - mse: 5.0981 - val_loss: 27.5038 - val_mse: 27.4977\n",
      "Epoch 21/30\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 4.4376 - mse: 4.4313 - val_loss: 27.5137 - val_mse: 27.5072\n",
      "Epoch 22/30\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 3.8629 - mse: 3.8562 - val_loss: 27.5105 - val_mse: 27.5036\n",
      "Epoch 23/30\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 3.3735 - mse: 3.3665 - val_loss: 27.5093 - val_mse: 27.5022\n",
      "Epoch 24/30\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 2.9482 - mse: 2.9409 - val_loss: 27.5065 - val_mse: 27.4991\n",
      "Epoch 25/30\n",
      "9000/9000 [==============================] - ETA: 0s - loss: 2.6028 - mse: 2.595 - 0s 47us/step - loss: 2.5831 - mse: 2.5755 - val_loss: 27.5021 - val_mse: 27.4944\n",
      "Epoch 26/30\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 2.2676 - mse: 2.2597 - val_loss: 27.4915 - val_mse: 27.4835\n",
      "Epoch 27/30\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 1.9922 - mse: 1.9841 - val_loss: 27.4953 - val_mse: 27.4870\n",
      "Epoch 28/30\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 1.7541 - mse: 1.7457 - val_loss: 27.4887 - val_mse: 27.4802\n",
      "Epoch 29/30\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 1.5447 - mse: 1.5361 - val_loss: 27.4827 - val_mse: 27.4740\n",
      "Epoch 30/30\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 1.3640 - mse: 1.3552 - val_loss: 27.4772 - val_mse: 27.4683\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: 1,\n",
      "Minimum RMSE at epoch: 2 = 5.233136944110332\n"
     ]
    }
   ],
   "source": [
    "# Define constants\n",
    "#K_FACTORS = 100 # The number of dimensional embeddings for books and users\n",
    "TEST_USER = 6293\n",
    "\n",
    "model1 = RecommenderV1(n_users, n_books, n_factors)\n",
    "compile_fit_plot(model1, 1)\n",
    "\n",
    "# user_ratings_1, recommendations_1 = predict_recommend(model1,TEST_USER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsmPj7Wq1cyS"
   },
   "source": [
    "**4.2 Plot the RMSE values during the training phase, as well as the model loss. Report the best RMSE. Is it better than the RMSE from the models we built in Section 2 and 3 ? (0.75 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCJFqfDm1-HA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LVLaC5K11-fN"
   },
   "source": [
    "**4.3 Use your trained model to recommend books for user with ID 6293. (0.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHQrNa35Jmjo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwpOi51caTUp"
   },
   "source": [
    "## How long did it take you to solve the homework?\n",
    "\n",
    "* Please answer as precisely as you can. It does not affect your points or grade in any way. It is okay, if it took 0.5 hours or 24 hours. The collected information will be used to improve future homeworks.\n",
    "\n",
    "<font color='red'> **Answer:**</font>\n",
    "\n",
    "**<font color='red'>(please change X in the next cell into your estimate)</font>**\n",
    "\n",
    "X hours\n",
    "\n",
    "## What is the level of difficulty for this homework?\n",
    "you can put only number between $0:10$ ($0:$ easy, $10:$ difficult)\n",
    "\n",
    "<font color='red'> **Answer:**</font>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Homework_04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
